import numpy as np
import os
import re
import datetime
import arxiv
import openai, tenacity
import base64, requests
import argparse
import configparser
import fitz, io, os
from PIL import Image
import gradio
import markdown

class Paper:
    def __init__(self, path, title='', url='', abs='', authers=[], sl=[]):
        # åˆå§‹åŒ–å‡½æ•°ï¼Œæ ¹æ®pdfè·¯å¾„åˆå§‹åŒ–Paperå¯¹è±¡                
        self.url =  url           # æ–‡ç« é“¾æ¥
        self.path = path          # pdfè·¯å¾„
        self.sl = sl
        self.section_names = []   # æ®µè½æ ‡é¢˜
        self.section_texts = {}   # æ®µè½å†…å®¹    
        if title == '':
            self.pdf = fitz.open(self.path) # pdfæ–‡æ¡£
            self.title = self.get_title()
            self.parse_pdf()            
        else:
            self.title = title
        self.authers = authers
        self.abs = abs
        self.roman_num = ["I", "II", 'III', "IV", "V", "VI", "VII", "VIII", "IIX", "IX", "X"]
        self.digit_num = [str(d+1) for d in range(10)]
        self.first_image = ''
        
    def parse_pdf(self):
        self.pdf = fitz.open(self.path) # pdfæ–‡æ¡£
        self.text_list = [page.get_text() for page in self.pdf]
        self.all_text = ' '.join(self.text_list)
        self.section_page_dict = self._get_all_page_index() # æ®µè½ä¸é¡µç çš„å¯¹åº”å­—å…¸
        print("section_page_dict", self.section_page_dict)
        self.section_text_dict = self._get_all_page() # æ®µè½ä¸å†…å®¹çš„å¯¹åº”å­—å…¸
        self.section_text_dict.update({"title": self.title})
        self.pdf.close()           
        
    def get_image_path(self, image_path=''):
        """
        å°†PDFä¸­çš„ç¬¬ä¸€å¼ å›¾ä¿å­˜åˆ°image.pngé‡Œé¢ï¼Œå­˜åˆ°æœ¬åœ°ç›®å½•ï¼Œè¿”å›æ–‡ä»¶åç§°ï¼Œä¾›giteeè¯»å–
        :param filename: å›¾ç‰‡æ‰€åœ¨è·¯å¾„ï¼Œ"C:\\Users\\Administrator\\Desktop\\nwd.pdf"
        :param image_path: å›¾ç‰‡æå–åçš„ä¿å­˜è·¯å¾„
        :return:
        """
        # open file
        max_size = 0
        image_list = []
        with fitz.Document(self.path) as my_pdf_file:
            # éå†æ‰€æœ‰é¡µé¢
            for page_number in range(1, len(my_pdf_file) + 1):
                # æŸ¥çœ‹ç‹¬ç«‹é¡µé¢
                page = my_pdf_file[page_number - 1]
                # æŸ¥çœ‹å½“å‰é¡µæ‰€æœ‰å›¾ç‰‡
                images = page.get_images()                
                # éå†å½“å‰é¡µé¢æ‰€æœ‰å›¾ç‰‡
                for image_number, image in enumerate(page.get_images(), start=1):           
                    # è®¿é—®å›¾ç‰‡xref
                    xref_value = image[0]
                    # æå–å›¾ç‰‡ä¿¡æ¯
                    base_image = my_pdf_file.extract_image(xref_value)
                    # è®¿é—®å›¾ç‰‡
                    image_bytes = base_image["image"]
                    # è·å–å›¾ç‰‡æ‰©å±•å
                    ext = base_image["ext"]
                    # åŠ è½½å›¾ç‰‡
                    image = Image.open(io.BytesIO(image_bytes))
                    image_size = image.size[0] * image.size[1]
                    if image_size > max_size:
                        max_size = image_size
                    image_list.append(image)
        for image in image_list:                            
            image_size = image.size[0] * image.size[1]
            if image_size == max_size:                
                image_name = f"image.{ext}"
                im_path = os.path.join(image_path, image_name)
                print("im_path:", im_path)
                
                max_pix = 480
                origin_min_pix = min(image.size[0], image.size[1])
                
                if image.size[0] > image.size[1]:
                    min_pix = int(image.size[1] * (max_pix/image.size[0]))
                    newsize = (max_pix, min_pix)
                else:
                    min_pix = int(image.size[0] * (max_pix/image.size[1]))
                    newsize = (min_pix, max_pix)
                image = image.resize(newsize)
                
                image.save(open(im_path, "wb"))
                return im_path, ext
        return None, None
    
    # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œæ ¹æ®å­—ä½“çš„å¤§å°ï¼Œè¯†åˆ«æ¯ä¸ªç« èŠ‚åç§°ï¼Œå¹¶è¿”å›ä¸€ä¸ªåˆ—è¡¨
    def get_chapter_names(self,):
        # # æ‰“å¼€ä¸€ä¸ªpdfæ–‡ä»¶
        doc = fitz.open(self.path) # pdfæ–‡æ¡£        
        text_list = [page.get_text() for page in doc]
        all_text = ''
        for text in text_list:
            all_text += text
        # # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨ç« èŠ‚åç§°
        chapter_names = []
        for line in all_text.split('\n'):
            line_list = line.split(' ')
            if '.' in line:
                point_split_list = line.split('.')
                space_split_list = line.split(' ')
                if 1 < len(space_split_list) < 5:
                    if 1 < len(point_split_list) < 5 and (point_split_list[0] in self.roman_num or point_split_list[0] in self.digit_num):
                        print("line:", line)
                        chapter_names.append(line)        
        
        return chapter_names
        
    def get_title(self):
        doc = self.pdf # æ‰“å¼€pdfæ–‡ä»¶
        max_font_size = 0 # åˆå§‹åŒ–æœ€å¤§å­—ä½“å¤§å°ä¸º0
        max_string = "" # åˆå§‹åŒ–æœ€å¤§å­—ä½“å¤§å°å¯¹åº”çš„å­—ç¬¦ä¸²ä¸ºç©º
        max_font_sizes = [0]
        for page in doc: # éå†æ¯ä¸€é¡µ
            text = page.get_text("dict") # è·å–é¡µé¢ä¸Šçš„æ–‡æœ¬ä¿¡æ¯
            blocks = text["blocks"] # è·å–æ–‡æœ¬å—åˆ—è¡¨
            for block in blocks: # éå†æ¯ä¸ªæ–‡æœ¬å—
                if block["type"] == 0: # å¦‚æœæ˜¯æ–‡å­—ç±»å‹
                    font_size = block["lines"][0]["spans"][0]["size"] # è·å–ç¬¬ä¸€è¡Œç¬¬ä¸€æ®µæ–‡å­—çš„å­—ä½“å¤§å°            
                    max_font_sizes.append(font_size)
                    if font_size > max_font_size: # å¦‚æœå­—ä½“å¤§å°å¤§äºå½“å‰æœ€å¤§å€¼
                        max_font_size = font_size # æ›´æ–°æœ€å¤§å€¼
                        max_string = block["lines"][0]["spans"][0]["text"] # æ›´æ–°æœ€å¤§å€¼å¯¹åº”çš„å­—ç¬¦ä¸²
        max_font_sizes.sort()                
        print("max_font_sizes", max_font_sizes[-10:])
        cur_title = ''
        for page in doc: # éå†æ¯ä¸€é¡µ
            text = page.get_text("dict") # è·å–é¡µé¢ä¸Šçš„æ–‡æœ¬ä¿¡æ¯
            blocks = text["blocks"] # è·å–æ–‡æœ¬å—åˆ—è¡¨
            for block in blocks: # éå†æ¯ä¸ªæ–‡æœ¬å—
                if block["type"] == 0: # å¦‚æœæ˜¯æ–‡å­—ç±»å‹
                    cur_string = block["lines"][0]["spans"][0]["text"] # æ›´æ–°æœ€å¤§å€¼å¯¹åº”çš„å­—ç¬¦ä¸²
                    font_flags = block["lines"][0]["spans"][0]["flags"] # è·å–ç¬¬ä¸€è¡Œç¬¬ä¸€æ®µæ–‡å­—çš„å­—ä½“ç‰¹å¾
                    font_size = block["lines"][0]["spans"][0]["size"] # è·å–ç¬¬ä¸€è¡Œç¬¬ä¸€æ®µæ–‡å­—çš„å­—ä½“å¤§å°                         
                    # print(font_size)
                    if abs(font_size - max_font_sizes[-1]) < 0.3 or abs(font_size - max_font_sizes[-2]) < 0.3:                        
                        # print("The string is bold.", max_string, "font_size:", font_size, "font_flags:", font_flags)                            
                        if len(cur_string) > 4 and "arXiv" not in cur_string:                            
                            # print("The string is bold.", max_string, "font_size:", font_size, "font_flags:", font_flags) 
                            if cur_title == ''    :
                                cur_title += cur_string                       
                            else:
                                cur_title += ' ' + cur_string                       
                            # break
        title = cur_title.replace('\n', ' ')                        
        return title

    def _get_all_page_index(self):
        # å®šä¹‰éœ€è¦å¯»æ‰¾çš„ç« èŠ‚åç§°åˆ—è¡¨
        section_list = self.sl
        # åˆå§‹åŒ–ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨æ‰¾åˆ°çš„ç« èŠ‚å’Œå®ƒä»¬åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„é¡µç 
        section_page_dict = {}
        # éå†æ¯ä¸€é¡µæ–‡æ¡£
        for page_index, page in enumerate(self.pdf):
            # è·å–å½“å‰é¡µé¢çš„æ–‡æœ¬å†…å®¹
            cur_text = page.get_text()
            # éå†éœ€è¦å¯»æ‰¾çš„ç« èŠ‚åç§°åˆ—è¡¨
            for section_name in section_list:
                # å°†ç« èŠ‚åç§°è½¬æ¢æˆå¤§å†™å½¢å¼
                section_name_upper = section_name.upper()
                # å¦‚æœå½“å‰é¡µé¢åŒ…å«"Abstract"è¿™ä¸ªå…³é”®è¯
                if "Abstract" == section_name and section_name in cur_text:
                    # å°†"Abstract"å’Œå®ƒæ‰€åœ¨çš„é¡µç åŠ å…¥å­—å…¸ä¸­
                    section_page_dict[section_name] = page_index
                # å¦‚æœå½“å‰é¡µé¢åŒ…å«ç« èŠ‚åç§°ï¼Œåˆ™å°†ç« èŠ‚åç§°å’Œå®ƒæ‰€åœ¨çš„é¡µç åŠ å…¥å­—å…¸ä¸­
                else:
                    if section_name + '\n' in cur_text:
                        section_page_dict[section_name] = page_index
                    elif section_name_upper + '\n' in cur_text:
                        section_page_dict[section_name] = page_index
        # è¿”å›æ‰€æœ‰æ‰¾åˆ°çš„ç« èŠ‚åç§°åŠå®ƒä»¬åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„é¡µç 
        return section_page_dict

    def _get_all_page(self):
        """
        è·å–PDFæ–‡ä»¶ä¸­æ¯ä¸ªé¡µé¢çš„æ–‡æœ¬ä¿¡æ¯ï¼Œå¹¶å°†æ–‡æœ¬ä¿¡æ¯æŒ‰ç…§ç« èŠ‚ç»„ç»‡æˆå­—å…¸è¿”å›ã€‚
        Returns:
            section_dict (dict): æ¯ä¸ªç« èŠ‚çš„æ–‡æœ¬ä¿¡æ¯å­—å…¸ï¼Œkeyä¸ºç« èŠ‚åï¼Œvalueä¸ºç« èŠ‚æ–‡æœ¬ã€‚
        """
        text = ''
        text_list = []
        section_dict = {}

        # # å…ˆå¤„ç†Abstractç« èŠ‚
        # for page_index, page in enumerate(self.pdf):
        #     cur_text = page.get_text()
        #     # å¦‚æœè¯¥é¡µé¢æ˜¯Abstractç« èŠ‚æ‰€åœ¨é¡µé¢
        #     if page_index == list(self.section_page_dict.values())[0]:
        #         abs_str = "Abstract"
        #         # è·å–Abstractç« èŠ‚çš„èµ·å§‹ä½ç½®
        #         first_index = cur_text.find(abs_str)
        #         # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªç« èŠ‚çš„å…³é”®è¯ï¼Œè¿™é‡Œæ˜¯Introduction
        #         intro_str = "Introduction"
        #         if intro_str in cur_text:
        #             second_index = cur_text.find(intro_str)
        #         elif intro_str.upper() in cur_text:
        #             second_index = cur_text.find(intro_str.upper())
        #         # å°†Abstractç« èŠ‚å†…å®¹åŠ å…¥å­—å…¸ä¸­
        #         section_dict[abs_str] = cur_text[first_index+len(abs_str)+1:second_index].replace('-\n',
        #                                                                                         '').replace('\n', ' ').split('I.')[0].split("II.")[0]

        # å†å¤„ç†å…¶ä»–ç« èŠ‚ï¼š
        text_list = [page.get_text() for page in self.pdf]
        for sec_index, sec_name in enumerate(self.section_page_dict):
            print(sec_index, sec_name, self.section_page_dict[sec_name])
            if sec_index <= 0:
                continue
            else:
                # ç›´æ¥è€ƒè™‘åé¢çš„å†…å®¹ï¼š
                start_page = self.section_page_dict[sec_name]
                if sec_index < len(list(self.section_page_dict.keys()))-1:
                    end_page = self.section_page_dict[list(self.section_page_dict.keys())[sec_index+1]]
                else:
                    end_page = len(text_list)
                print("start_page, end_page:", start_page, end_page)
                cur_sec_text = ''
                if end_page - start_page == 0:
                    if sec_index < len(list(self.section_page_dict.keys()))-1:
                        next_sec = list(self.section_page_dict.keys())[sec_index+1]
                        if text_list[start_page].find(sec_name) == -1:
                            start_i = text_list[start_page].find(sec_name.upper())
                        else:
                            start_i = text_list[start_page].find(sec_name)
                        if text_list[start_page].find(next_sec) == -1:
                            end_i = text_list[start_page].find(next_sec.upper())
                        else:
                            end_i = text_list[start_page].find(next_sec)                        
                        cur_sec_text += text_list[start_page][start_i:end_i]
                else:
                    for page_i in range(start_page, end_page):                    
#                         print("page_i:", page_i)
                        if page_i == start_page:
                            if text_list[start_page].find(sec_name) == -1:
                                start_i = text_list[start_page].find(sec_name.upper())
                            else:
                                start_i = text_list[start_page].find(sec_name)
                            cur_sec_text += text_list[page_i][start_i:]
                        elif page_i < end_page:
                            cur_sec_text += text_list[page_i]
                        elif page_i == end_page:
                            if sec_index < len(list(self.section_page_dict.keys()))-1:
                                next_sec = list(self.section_page_dict.keys())[sec_index+1]
                                if text_list[start_page].find(next_sec) == -1:
                                    end_i = text_list[start_page].find(next_sec.upper())
                                else:
                                    end_i = text_list[start_page].find(next_sec)  
                                cur_sec_text += text_list[page_i][:end_i]
                section_dict[sec_name] = cur_sec_text.replace('-\n', '').replace('\n', ' ')
        return section_dict

# å®šä¹‰Readerç±»
class Reader:
    # åˆå§‹åŒ–æ–¹æ³•ï¼Œè®¾ç½®å±æ€§
    def __init__(self, key_word='', query='', filter_keys='', 
                 root_path='./',
                 gitee_key='',
                 sort=arxiv.SortCriterion.SubmittedDate, user_name='defualt', language='cn', key=''):
        self.key = str(key) # OpenAI key
        self.user_name = user_name # è¯»è€…å§“å
        self.key_word = key_word # è¯»è€…æ„Ÿå…´è¶£çš„å…³é”®è¯
        self.query = query # è¯»è€…è¾“å…¥çš„æœç´¢æŸ¥è¯¢
        self.sort = sort # è¯»è€…é€‰æ‹©çš„æ’åºæ–¹å¼
        self.language = language # è¯»è€…é€‰æ‹©çš„è¯­è¨€        
        self.filter_keys = filter_keys # ç”¨äºåœ¨æ‘˜è¦ä¸­ç­›é€‰çš„å…³é”®è¯
        self.root_path = root_path
        self.file_format = 'md' # or 'txt'ï¼Œå¦‚æœä¸ºå›¾ç‰‡ï¼Œåˆ™å¿…é¡»ä¸º'md'
        self.save_image = False
        if self.save_image:
            self.gitee_key = self.config.get('Gitee', 'api')
        else:
            self.gitee_key = ''
                
    def get_arxiv(self, max_results=30):
        search = arxiv.Search(query=self.query,
                              max_results=max_results,                              
                              sort_by=self.sort,
                              sort_order=arxiv.SortOrder.Descending,
                              )       
        return search
     
    def filter_arxiv(self, max_results=30):
        search = self.get_arxiv(max_results=max_results)
        print("all search:")
        for index, result in enumerate(search.results()):
            print(index, result.title, result.updated)
            
        filter_results = []   
        filter_keys = self.filter_keys
        
        print("filter_keys:", self.filter_keys)
        # ç¡®ä¿æ¯ä¸ªå…³é”®è¯éƒ½èƒ½åœ¨æ‘˜è¦ä¸­æ‰¾åˆ°ï¼Œæ‰ç®—æ˜¯ç›®æ ‡è®ºæ–‡
        for index, result in enumerate(search.results()):
            abs_text = result.summary.replace('-\n', '-').replace('\n', ' ')
            meet_num = 0
            for f_key in filter_keys.split(" "):
                if f_key.lower() in abs_text.lower():
                    meet_num += 1
            if meet_num == len(filter_keys.split(" ")):
                filter_results.append(result)
                # break
        print("filter_results:", len(filter_results))
        print("filter_papers:")
        for index, result in enumerate(filter_results):
            print(index, result.title, result.updated)
        return filter_results
    
    def validateTitle(self, title):
        # å°†è®ºæ–‡çš„ä¹±ä¸ƒå…«ç³Ÿçš„è·¯å¾„æ ¼å¼ä¿®æ­£
        rstr = r"[\/\\\:\*\?\"\<\>\|]" # '/ \ : * ? " < > |'
        new_title = re.sub(rstr, "_", title) # æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
        return new_title

    def download_pdf(self, filter_results):
        # å…ˆåˆ›å»ºæ–‡ä»¶å¤¹
        date_str = str(datetime.datetime.now())[:13].replace(' ', '-')        
        key_word = str(self.key_word.replace(':', ' '))        
        path = self.root_path  + 'pdf_files/' + self.query.replace('au: ', '').replace('title: ', '').replace('ti: ', '').replace(':', ' ')[:25] + '-' + date_str
        try:
            os.makedirs(path)
        except:
            pass
        print("All_paper:", len(filter_results))
        # å¼€å§‹ä¸‹è½½ï¼š
        paper_list = []
        for r_index, result in enumerate(filter_results):
            try:
                title_str = self.validateTitle(result.title)
                pdf_name = title_str+'.pdf'
                # result.download_pdf(path, filename=pdf_name)
                self.try_download_pdf(result, path, pdf_name)
                paper_path = os.path.join(path, pdf_name)
                print("paper_path:", paper_path)
                paper = Paper(path=paper_path,
                              url=result.entry_id,
                              title=result.title,
                              abs=result.summary.replace('-\n', '-').replace('\n', ' '),
                              authers=[str(aut) for aut in result.authors],
                              )
                # ä¸‹è½½å®Œæ¯•ï¼Œå¼€å§‹è§£æï¼š
                paper.parse_pdf()
                paper_list.append(paper)
            except Exception as e:
                print("download_error:", e)
                pass
        return paper_list
    
    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)
    def try_download_pdf(self, result, path, pdf_name):
        result.download_pdf(path, filename=pdf_name)
    
    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)
    def upload_gitee(self, image_path, image_name='', ext='png'):
        """
        ä¸Šä¼ åˆ°ç äº‘
        :return:
        """ 
        with open(image_path, 'rb') as f:
            base64_data = base64.b64encode(f.read())
            base64_content = base64_data.decode()
        
        date_str = str(datetime.datetime.now())[:19].replace(':', '-').replace(' ', '-') + '.' + ext
        path = image_name+ '-' +date_str
        
        payload = {
            "access_token": self.gitee_key,
            "owner": self.config.get('Gitee', 'owner'),
            "repo": self.config.get('Gitee', 'repo'),
            "path": self.config.get('Gitee', 'path'),
            "content": base64_content,
            "message": "upload image"
        }
        # è¿™é‡Œéœ€è¦ä¿®æ”¹æˆä½ çš„giteeçš„è´¦æˆ·å’Œä»“åº“åï¼Œä»¥åŠæ–‡ä»¶å¤¹çš„åå­—ï¼š
        url = f'https://gitee.com/api/v5/repos/'+self.config.get('Gitee', 'owner')+'/'+self.config.get('Gitee', 'repo')+'/contents/'+self.config.get('Gitee', 'path')+'/'+path
        rep = requests.post(url, json=payload).json()
        print("rep:", rep)
        if 'content' in rep.keys():
            image_url = rep['content']['download_url']
        else:
            image_url = r"https://gitee.com/api/v5/repos/"+self.config.get('Gitee', 'owner')+'/'+self.config.get('Gitee', 'repo')+'/contents/'+self.config.get('Gitee', 'path')+'/' + path
            
        return image_url
    
    def summary_with_chat(self, paper_list, key):
        htmls = []
        for paper_index, paper in enumerate(paper_list):
            # ç¬¬ä¸€æ­¥å…ˆç”¨titleï¼Œabsï¼Œå’Œintroductionè¿›è¡Œæ€»ç»“ã€‚
            text = ''
            text += 'Title:' + paper.title
            text += 'Url:' + paper.url
            text += 'Abstrat:' + paper.abs
            # intro
            text += list(paper.section_text_dict.values())[0]
            max_token = 2500 * 4
            text = text[:max_token]
            chat_summary_text = self.chat_summary(text=text, key=str(key))           
            htmls.append(chat_summary_text)
            
            # TODO å¾€mdæ–‡æ¡£ä¸­æ’å…¥è®ºæ–‡é‡Œçš„åƒç´ æœ€å¤§çš„ä¸€å¼ å›¾ç‰‡ï¼Œè¿™ä¸ªæ–¹æ¡ˆå¯ä»¥å¼„çš„æ›´åŠ æ™ºèƒ½ä¸€äº›ï¼š
            first_image, ext = paper.get_image_path()
            if first_image is None or self.gitee_key == '':
                pass
            else:                
                image_title = self.validateTitle(paper.title)
                image_url = self.upload_gitee(image_path=first_image, image_name=image_title, ext=ext)
                htmls.append("\n")
                htmls.append("![Fig]("+image_url+")")
                htmls.append("\n")
            # ç¬¬äºŒæ­¥æ€»ç»“æ–¹æ³•ï¼š
            # TODOï¼Œç”±äºæœ‰äº›æ–‡ç« çš„æ–¹æ³•ç« èŠ‚åæ˜¯ç®—æ³•åï¼Œæ‰€ä»¥ç®€å•çš„é€šè¿‡å…³é”®è¯æ¥ç­›é€‰ï¼Œå¾ˆéš¾è·å–ï¼Œåé¢éœ€è¦ç”¨å…¶ä»–çš„æ–¹æ¡ˆå»ä¼˜åŒ–ã€‚
            method_key = ''
            for parse_key in paper.section_text_dict.keys():
                if 'method' in parse_key.lower() or 'approach' in parse_key.lower():
                    method_key = parse_key
                    break
                
            if method_key != '':
                text = ''
                method_text = ''
                summary_text = ''
                summary_text += "<summary>" + chat_summary_text
                # methods                
                method_text += paper.section_text_dict[method_key]   
                # TODO æŠŠè¿™ä¸ªå˜æˆtenacityçš„è‡ªåŠ¨åˆ¤åˆ«ï¼             
                max_token = 2500 * 4
                text = summary_text + "\n <Methods>:\n" + method_text 
                text = text[:max_token]
                chat_method_text = self.chat_method(text=text, key=str(key))
                htmls.append(chat_method_text)
            else:
                chat_method_text = ''
            htmls.append("\n")
            
            # ç¬¬ä¸‰æ­¥æ€»ç»“å…¨æ–‡ï¼Œå¹¶æ‰“åˆ†ï¼š
            conclusion_key = ''
            for parse_key in paper.section_text_dict.keys():
                if 'conclu' in parse_key.lower():
                    conclusion_key = parse_key
                    break
            
            text = ''
            conclusion_text = ''
            summary_text = ''
            summary_text += "<summary>" + chat_summary_text + "\n <Method summary>:\n" + chat_method_text            
            if conclusion_key != '':
                # conclusion                
                conclusion_text += paper.section_text_dict[conclusion_key]                
                max_token = 2500 * 4
                text = summary_text + "\n <Conclusion>:\n" + conclusion_text 
            else:
                text = summary_text
            text = text[:max_token]
            chat_conclusion_text = self.chat_conclusion(text=text, key=str(key))
            htmls.append(chat_conclusion_text)
            htmls.append("\n")
            md_text = "\n".join(htmls)
            
            return markdown.markdown(md_text)
            
            
    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)
    def chat_conclusion(self, text, key):
        openai.api_key = key
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            # promptéœ€è¦ç”¨è‹±è¯­æ›¿æ¢ï¼Œå°‘å ç”¨tokenã€‚
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª["+self.key_word+"]é¢†åŸŸçš„å®¡ç¨¿äººï¼Œä½ éœ€è¦ä¸¥æ ¼è¯„å®¡è¿™ç¯‡æ–‡ç« "},  # chatgpt è§’è‰²
                {"role": "assistant", "content": "è¿™æ˜¯ä¸€ç¯‡è‹±æ–‡æ–‡çŒ®çš„<summary>å’Œ<conclusion>éƒ¨åˆ†å†…å®¹ï¼Œå…¶ä¸­<summary>ä½ å·²ç»æ€»ç»“å¥½äº†ï¼Œä½†æ˜¯<conclusion>éƒ¨åˆ†ï¼Œæˆ‘éœ€è¦ä½ å¸®å¿™å½’çº³ä¸‹é¢é—®é¢˜ï¼š"+text},  # èƒŒæ™¯çŸ¥è¯†ï¼Œå¯ä»¥å‚è€ƒOpenReviewçš„å®¡ç¨¿æµç¨‹
                {"role": "user", "content": """                 
                 8. åšå‡ºå¦‚ä¸‹æ€»ç»“ï¼š
                    - (1):è¿™ç¯‡å·¥ä½œçš„æ„ä¹‰å¦‚ä½•ï¼Ÿ
                    - (2):ä»åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡è¿™ä¸‰ä¸ªç»´åº¦ï¼Œæ€»ç»“è¿™ç¯‡æ–‡ç« çš„ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚                   
                    .......
                 æŒ‰ç…§åé¢çš„æ ¼å¼è¾“å‡º: 
                 8. Conclusion:
                    - (1):xxx;                     
                    - (2):åˆ›æ–°ç‚¹: xxx; æ€§èƒ½: xxx; å·¥ä½œé‡: xxx;                      
                 
                 åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯éœ€è¦ç”¨è‹±æ–‡æ ‡æ³¨)ï¼Œè¯­å¥å°½é‡ç®€æ´ä¸”å­¦æœ¯ï¼Œä¸è¦å’Œä¹‹å‰çš„<summary>å†…å®¹é‡å¤ï¼Œæ•°å€¼ä½¿ç”¨åŸæ–‡æ•°å­—, åŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå°†å¯¹åº”å†…å®¹è¾“å‡ºåˆ°xxxä¸­ï¼Œ.......ä»£è¡¨æŒ‰ç…§å®é™…éœ€æ±‚å¡«å†™ï¼Œå¦‚æœæ²¡æœ‰å¯ä»¥ä¸ç”¨å†™.                 
                 """},
            ]
        )
        result = ''
        for choice in response.choices:
            result += choice.message.content
        print("conclusion_result:\n", result)
        return result            
    
    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)
    def chat_method(self, text, key):
        openai.api_key = key
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª["+self.key_word+"]é¢†åŸŸçš„ç§‘ç ”äººå‘˜ï¼Œå–„äºä½¿ç”¨ç²¾ç‚¼çš„è¯­å¥æ€»ç»“è®ºæ–‡"},  # chatgpt è§’è‰²
                {"role": "assistant", "content": "è¿™æ˜¯ä¸€ç¯‡è‹±æ–‡æ–‡çŒ®çš„<summary>å’Œ<Method>éƒ¨åˆ†å†…å®¹ï¼Œå…¶ä¸­<summary>ä½ å·²ç»æ€»ç»“å¥½äº†ï¼Œä½†æ˜¯<Methods>éƒ¨åˆ†ï¼Œæˆ‘éœ€è¦ä½ å¸®å¿™é˜…è¯»å¹¶å½’çº³ä¸‹é¢é—®é¢˜ï¼š"+text},  # èƒŒæ™¯çŸ¥è¯†
                {"role": "user", "content": """                 
                 7. è¯¦ç»†æè¿°è¿™ç¯‡æ–‡ç« çš„æ–¹æ³•æ€è·¯ã€‚æ¯”å¦‚è¯´å®ƒçš„æ­¥éª¤æ˜¯ï¼š
                    - (1):...
                    - (2):...
                    - (3):...
                    - .......
                 æŒ‰ç…§åé¢çš„æ ¼å¼è¾“å‡º: 
                 7. Methods:
                    - (1):xxx; 
                    - (2):xxx; 
                    - (3):xxx;  
                    .......     
                 
                 åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯éœ€è¦ç”¨è‹±æ–‡æ ‡æ³¨)ï¼Œè¯­å¥å°½é‡ç®€æ´ä¸”å­¦æœ¯ï¼Œä¸è¦å’Œä¹‹å‰çš„<summary>å†…å®¹é‡å¤ï¼Œæ•°å€¼ä½¿ç”¨åŸæ–‡æ•°å­—, åŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå°†å¯¹åº”å†…å®¹è¾“å‡ºåˆ°xxxä¸­ï¼ŒæŒ‰ç…§\næ¢è¡Œï¼Œ.......ä»£è¡¨æŒ‰ç…§å®é™…éœ€æ±‚å¡«å†™ï¼Œå¦‚æœæ²¡æœ‰å¯ä»¥ä¸ç”¨å†™.                 
                 """},
            ]
        )
        result = ''
        for choice in response.choices:
            result += choice.message.content
        print("method_result:\n", result)
        return result
    
    @tenacity.retry(wait=tenacity.wait_exponential(multiplier=1, min=4, max=10),
                    stop=tenacity.stop_after_attempt(5),
                    reraise=True)
    def chat_summary(self, text, key):
        openai.api_key = key
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ª["+self.key_word+"]é¢†åŸŸçš„ç§‘ç ”äººå‘˜ï¼Œå–„äºä½¿ç”¨ç²¾ç‚¼çš„è¯­å¥æ€»ç»“è®ºæ–‡"},  # chatgpt è§’è‰²
                {"role": "assistant", "content": "è¿™æ˜¯ä¸€ç¯‡è‹±æ–‡æ–‡çŒ®çš„æ ‡é¢˜ï¼Œä½œè€…ï¼Œé“¾æ¥ï¼ŒAbstractå’ŒIntroductionéƒ¨åˆ†å†…å®¹ï¼Œæˆ‘éœ€è¦ä½ å¸®å¿™é˜…è¯»å¹¶å½’çº³ä¸‹é¢é—®é¢˜ï¼š"+text},  # èƒŒæ™¯çŸ¥è¯†
                {"role": "user", "content": """                 
                 1. æ ‡è®°å‡ºè¿™ç¯‡æ–‡çŒ®çš„æ ‡é¢˜(åŠ ä¸Šä¸­æ–‡ç¿»è¯‘)
                 2. åˆ—ä¸¾æ‰€æœ‰çš„ä½œè€…å§“å (ä½¿ç”¨è‹±æ–‡)
                 3. æ ‡è®°ç¬¬ä¸€ä½œè€…çš„å•ä½ï¼ˆåªè¾“å‡ºä¸­æ–‡ç¿»è¯‘ï¼‰                 
                 4. æ ‡è®°å‡ºè¿™ç¯‡æ–‡ç« çš„å…³é”®è¯(ä½¿ç”¨è‹±æ–‡)
                 5. è®ºæ–‡é“¾æ¥ï¼ŒGithubä»£ç é“¾æ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œæ²¡æœ‰çš„è¯è¯·å¡«å†™Github:Noneï¼‰
                 6. æŒ‰ç…§ä¸‹é¢å››ä¸ªç‚¹è¿›è¡Œæ€»ç»“ï¼š
                    - (1):è¿™ç¯‡æ–‡ç« çš„ç ”ç©¶èƒŒæ™¯æ˜¯ä»€ä¹ˆï¼Ÿ
                    - (2):è¿‡å»çš„æ–¹æ³•æœ‰å“ªäº›ï¼Ÿå®ƒä»¬å­˜åœ¨ä»€ä¹ˆé—®é¢˜ï¼Ÿæœ¬æ–‡å’Œè¿‡å»çš„ç ”ç©¶æœ‰å“ªäº›æœ¬è´¨çš„åŒºåˆ«ï¼ŸIs the approach well motivated?
                    - (3):æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ
                    - (4):æœ¬æ–‡æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šï¼Œå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½èƒ½å¦æ”¯æŒä»–ä»¬çš„ç›®æ ‡ï¼Ÿ
                 æŒ‰ç…§åé¢çš„æ ¼å¼è¾“å‡º:                  
                 1. Title: xxx
                 2. Authors: xxx
                 3. Affiliation: xxx                
                 4. Keywords: xxx   
                 5. Urls: xxx or xxx , xxx      
                 6. Summary:
                    - (1):xxx;
                    - (2):xxx;
                    - (3):xxx; 
                    - (4):xxx.    
                 
                 åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯éœ€è¦ç”¨è‹±æ–‡æ ‡æ³¨)ï¼Œè¯­å¥å°½é‡ç®€æ´ä¸”å­¦æœ¯ï¼Œä¸è¦æœ‰å¤ªå¤šé‡å¤çš„ä¿¡æ¯ï¼Œæ•°å€¼ä½¿ç”¨åŸæ–‡æ•°å­—, åŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå°†å¯¹åº”å†…å®¹è¾“å‡ºåˆ°xxxä¸­ï¼ŒæŒ‰ç…§\næ¢è¡Œ.                 
                 """},
            ]
        )
        result = ''
        for choice in response.choices:
            result += choice.message.content
        print("summary_result:\n", result)
        return result        
            
    def export_to_markdown(self, text, file_name, mode='w'):
        # ä½¿ç”¨markdownæ¨¡å—çš„convertæ–¹æ³•ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºhtmlæ ¼å¼
        # html = markdown.markdown(text)
        # æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ï¼Œä»¥å†™å…¥æ¨¡å¼
        with open(file_name, mode, encoding="utf-8") as f:
            # å°†htmlæ ¼å¼çš„å†…å®¹å†™å…¥æ–‡ä»¶
            f.write(text)        

    # å®šä¹‰ä¸€ä¸ªæ–¹æ³•ï¼Œæ‰“å°å‡ºè¯»è€…ä¿¡æ¯
    def show_info(self):        
        print(f"Key word: {self.key_word}")
        print(f"Query: {self.query}")
        print(f"Sort: {self.sort}")                

def upload_pdf(key, text, file):
    # æ£€æŸ¥ä¸¤ä¸ªè¾“å…¥éƒ½ä¸ä¸ºç©º
    if not key or not text or not file:
        return "ä¸¤ä¸ªè¾“å…¥éƒ½ä¸èƒ½ä¸ºç©ºï¼Œè¯·è¾“å…¥å­—ç¬¦å¹¶ä¸Šä¼  PDF æ–‡ä»¶ï¼"
    # åˆ¤æ–­PDFæ–‡ä»¶
    if file and file.name.split(".")[-1].lower() != "pdf":
        return 'è¯·å‹¿ä¸Šä¼ é PDF æ–‡ä»¶ï¼'
    else:
        section_list = text.split(',')
        paper_list = [Paper(path=file, sl=section_list)]
        # åˆ›å»ºä¸€ä¸ªReaderå¯¹è±¡
        reader = Reader()
        sum_info = reader.summary_with_chat(paper_list=paper_list, key=key)
        return sum_info

# æ ‡é¢˜
title = "ChatPaper <img src='https://visitor-badge.laobi.icu/badge?page_id=https://huggingface.co/spaces/wangrongsheng/ChatPaper'>"
# æè¿°
description = '''<div align='left'>

<img align='right' src='https://i.328888.xyz/2023/03/12/vH9dU.png' width="200">

Use ChatGPT to summary the papers.Star our Github [ğŸŒŸChatPaper](https://github.com/kaixindelele/ChatPaper) .

ğŸ’—å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼ğŸ’—

ğŸ”´è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼

</div>
'''
# åˆ›å»ºGradioç•Œé¢
ip = [
    gradio.inputs.Textbox(label="è¯·è¾“å…¥ä½ çš„API-key(å¿…å¡«)", default=""),
    gradio.inputs.Textbox(label="è¯·è¾“å…¥è®ºæ–‡å¤§æ ‡é¢˜ç´¢å¼•(ç”¨è‹±æ–‡é€—å·éš”å¼€,å¿…å¡«)", default="'Abstract,Introduction,Related Work,Background,Preliminary,Problem Formulation,Methods,Methodology,Method,Approach,Approaches,Materials and Methods,Experiment Settings,Experiment,Experimental Results,Evaluation,Experiments,Results,Findings,Data Analysis,Discussion,Results and Discussion,Conclusion,References'"),
    gradio.inputs.File(label="è¯·ä¸Šä¼ è®ºæ–‡PDF(å¿…å¡«)")
]

interface = gradio.Interface(fn=upload_pdf, inputs=ip, outputs="html", title=title, description=description)

# è¿è¡ŒGradioåº”ç”¨ç¨‹åº
interface.launch()